{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "69ce8857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "# import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6708d82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('D:\\\\Clinics_5\\\\refinedIPLDataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c061b22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteam1</th>\n",
       "      <th>iteam2</th>\n",
       "      <th>batting_first</th>\n",
       "      <th>iresult</th>\n",
       "      <th>margin</th>\n",
       "      <th>ground</th>\n",
       "      <th>neutral_venue</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>816 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iteam1  iteam2  batting_first  iresult  margin  ground  neutral_venue  y\n",
       "0        14       2              0        0     140       3              0  0\n",
       "1         4       3              0        0      33       7              0  0\n",
       "2         5       6              0        1       9       1              0  1\n",
       "3         1      14              1        1       5       2              0  0\n",
       "4         2       8              0        1       5      36              0  1\n",
       "..      ...     ...            ...      ...     ...     ...            ... ..\n",
       "811      14       1              1        2       0       8              0  1\n",
       "812       1      10              1        0      57       8              0  1\n",
       "813      14       7              1        1       6       9              0  0\n",
       "814      10       7              1        0      17       9              0  1\n",
       "815      10       1              1        1       5       8              0  0\n",
       "\n",
       "[816 rows x 8 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3a2feb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iteam1            14\n",
       "iteam2            14\n",
       "batting_first      1\n",
       "iresult            2\n",
       "margin           146\n",
       "ground            36\n",
       "neutral_venue      1\n",
       "y                  1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c603c07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteam1</th>\n",
       "      <th>iteam2</th>\n",
       "      <th>batting_first</th>\n",
       "      <th>iresult</th>\n",
       "      <th>margin</th>\n",
       "      <th>ground</th>\n",
       "      <th>neutral_venue</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.958904</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226027</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.061644</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.390411</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116438</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>816 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       iteam1    iteam2  batting_first  iresult    margin    ground  \\\n",
       "0    1.000000  0.142857            0.0      0.0  0.958904  0.083333   \n",
       "1    0.285714  0.214286            0.0      0.0  0.226027  0.194444   \n",
       "2    0.357143  0.428571            0.0      0.5  0.061644  0.027778   \n",
       "3    0.071429  1.000000            1.0      0.5  0.034247  0.055556   \n",
       "4    0.142857  0.571429            0.0      0.5  0.034247  1.000000   \n",
       "..        ...       ...            ...      ...       ...       ...   \n",
       "811  1.000000  0.071429            1.0      1.0  0.000000  0.222222   \n",
       "812  0.071429  0.714286            1.0      0.0  0.390411  0.222222   \n",
       "813  1.000000  0.500000            1.0      0.5  0.041096  0.250000   \n",
       "814  0.714286  0.500000            1.0      0.0  0.116438  0.250000   \n",
       "815  0.714286  0.071429            1.0      0.5  0.034247  0.222222   \n",
       "\n",
       "     neutral_venue    y  \n",
       "0              0.0  0.0  \n",
       "1              0.0  0.0  \n",
       "2              0.0  1.0  \n",
       "3              0.0  0.0  \n",
       "4              0.0  1.0  \n",
       "..             ...  ...  \n",
       "811            0.0  1.0  \n",
       "812            0.0  1.0  \n",
       "813            0.0  0.0  \n",
       "814            0.0  1.0  \n",
       "815            0.0  0.0  \n",
       "\n",
       "[816 rows x 8 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def absolute_maximum_scale(series):\n",
    "    return series / series.abs().max()\n",
    "for col in data.columns:\n",
    "    data[col] = absolute_maximum_scale(data[col])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "17680f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iteam1           1.0\n",
       "iteam2           1.0\n",
       "batting_first    1.0\n",
       "iresult          1.0\n",
       "margin           1.0\n",
       "ground           1.0\n",
       "neutral_venue    1.0\n",
       "y                1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "873599e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07142857, 0.21428571, 1.        , ..., 0.05555556, 0.        ,\n",
       "        1.        ],\n",
       "       [0.71428571, 0.5       , 1.        , ..., 0.02777778, 0.        ,\n",
       "        0.        ],\n",
       "       [0.35714286, 1.        , 0.        , ..., 0.02777778, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.28571429, 0.21428571, 0.        , ..., 0.19444444, 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.21428571, 0.        , ..., 0.66666667, 1.        ,\n",
       "        1.        ],\n",
       "       [0.85714286, 0.07142857, 1.        , ..., 0.30555556, 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "np.random.shuffle(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1e22d661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.357143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.328767</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.047945</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226027</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>816 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1    2    3         4         5    6    7\n",
       "0    0.071429  0.214286  1.0  0.0  0.054795  0.055556  0.0  1.0\n",
       "1    0.714286  0.500000  1.0  0.5  0.034247  0.027778  0.0  0.0\n",
       "2    0.357143  1.000000  0.0  0.0  0.027397  0.027778  0.0  0.0\n",
       "3    0.500000  0.142857  1.0  0.0  0.328767  0.111111  0.0  1.0\n",
       "4    1.000000  0.071429  0.0  0.0  0.041096  0.416667  0.0  0.0\n",
       "..        ...       ...  ...  ...       ...       ...  ...  ...\n",
       "811  0.285714  0.142857  1.0  0.5  0.047945  0.277778  0.0  0.0\n",
       "812  0.285714  0.357143  1.0  0.5  0.034247  0.194444  0.0  0.0\n",
       "813  0.285714  0.214286  0.0  0.0  0.226027  0.194444  0.0  0.0\n",
       "814  1.000000  0.214286  0.0  0.5  0.041096  0.666667  1.0  1.0\n",
       "815  0.857143  0.071429  1.0  0.5  0.054795  0.305556  0.0  0.0\n",
       "\n",
       "[816 rows x 8 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "09557125",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = data[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a4164ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.357143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.328767</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.047945</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226027</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>816 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1    2    3         4         5    6\n",
       "0    0.071429  0.214286  1.0  0.0  0.054795  0.055556  0.0\n",
       "1    0.714286  0.500000  1.0  0.5  0.034247  0.027778  0.0\n",
       "2    0.357143  1.000000  0.0  0.0  0.027397  0.027778  0.0\n",
       "3    0.500000  0.142857  1.0  0.0  0.328767  0.111111  0.0\n",
       "4    1.000000  0.071429  0.0  0.0  0.041096  0.416667  0.0\n",
       "..        ...       ...  ...  ...       ...       ...  ...\n",
       "811  0.285714  0.142857  1.0  0.5  0.047945  0.277778  0.0\n",
       "812  0.285714  0.357143  1.0  0.5  0.034247  0.194444  0.0\n",
       "813  0.285714  0.214286  0.0  0.0  0.226027  0.194444  0.0\n",
       "814  1.000000  0.214286  0.0  0.5  0.041096  0.666667  1.0\n",
       "815  0.857143  0.071429  1.0  0.5  0.054795  0.305556  0.0\n",
       "\n",
       "[816 rows x 7 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(7, axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5f8f7c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.357143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.328767</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.047945</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226027</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>816 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1    2    3         4         5    6\n",
       "0    0.071429  0.214286  1.0  0.0  0.054795  0.055556  0.0\n",
       "1    0.714286  0.500000  1.0  0.5  0.034247  0.027778  0.0\n",
       "2    0.357143  1.000000  0.0  0.0  0.027397  0.027778  0.0\n",
       "3    0.500000  0.142857  1.0  0.0  0.328767  0.111111  0.0\n",
       "4    1.000000  0.071429  0.0  0.0  0.041096  0.416667  0.0\n",
       "..        ...       ...  ...  ...       ...       ...  ...\n",
       "811  0.285714  0.142857  1.0  0.5  0.047945  0.277778  0.0\n",
       "812  0.285714  0.357143  1.0  0.5  0.034247  0.194444  0.0\n",
       "813  0.285714  0.214286  0.0  0.0  0.226027  0.194444  0.0\n",
       "814  1.000000  0.214286  0.0  0.5  0.041096  0.666667  1.0\n",
       "815  0.857143  0.071429  1.0  0.5  0.054795  0.305556  0.0\n",
       "\n",
       "[816 rows x 7 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = data\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e886c6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07142857, 0.21428571, 1.        , ..., 0.05479452, 0.05555556,\n",
       "        0.        ],\n",
       "       [0.71428571, 0.5       , 1.        , ..., 0.03424658, 0.02777778,\n",
       "        0.        ],\n",
       "       [0.35714286, 1.        , 0.        , ..., 0.02739726, 0.02777778,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.28571429, 0.21428571, 0.        , ..., 0.2260274 , 0.19444444,\n",
       "        0.        ],\n",
       "       [1.        , 0.21428571, 0.        , ..., 0.04109589, 0.66666667,\n",
       "        1.        ],\n",
       "       [0.85714286, 0.07142857, 1.        , ..., 0.05479452, 0.30555556,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = np.array(train_x), np.array(train_y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5ab95f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652 164 652 164\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = x[0:652], x[652::], y[0:652], y[652::]\n",
    "print(len(train_x), len(test_x), len(train_y), len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f2ce2837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "#     print('7777')\n",
    "#     s = 1/(1+np.exp(-z))\n",
    "    s = 1/(1+np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "94ddaee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def layer_sizes(X, Y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- input dataset of shape (input size, number of examples)\n",
    "    Y -- labels of shape (output size, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    n_x -- the size of the input layer\n",
    "    n_h -- the size of the hidden layer\n",
    "    n_y -- the size of the output layer\n",
    "    \"\"\"\n",
    "    #(â‰ˆ 3 lines of code)\n",
    "    # n_x = ... \n",
    "    # n_h = ...\n",
    "    # n_y = ... \n",
    "    # YOUR CODE STARTS HERE\n",
    "    n_x = X.shape[0]\n",
    "    n_h = 4\n",
    "    n_y = Y.shape[0]\n",
    "    # YOUR CODE ENDS HERE\n",
    "    return (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "70390d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    n_x -- size of the input layer\n",
    "    n_h -- size of the hidden layer\n",
    "    n_y -- size of the output layer\n",
    "    \n",
    "    Returns:\n",
    "    params -- python dictionary containing your parameters:\n",
    "                    W1 -- weight matrix of shape (n_h, n_x)\n",
    "                    b1 -- bias vector of shape (n_h, 1)\n",
    "                    W2 -- weight matrix of shape (n_y, n_h)\n",
    "                    b2 -- bias vector of shape (n_y, 1)\n",
    "    \"\"\"    \n",
    "    #(â‰ˆ 4 lines of code)\n",
    "    # W1 = ...\n",
    "    # b1 = ...\n",
    "    # W2 = ...\n",
    "    # b2 = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    W1 = np.random.randn(n_h,n_x) * 0.1\n",
    "    b1 = np.zeros((n_h,1))\n",
    "    W2 = np.random.randn(n_y,n_h) * 0.1\n",
    "    b2 = np.zeros((n_y,1))\n",
    "#     print(W1, W2)\n",
    "    # YOUR CODE ENDS HERE\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4d5b4418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION:forward_propagation\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    X -- input data of size (n_x, m)\n",
    "    parameters -- python dictionary containing your parameters (output of initialization function)\n",
    "    \n",
    "    Returns:\n",
    "    A2 -- The sigmoid output of the second activation\n",
    "    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\"\n",
    "    \"\"\"\n",
    "    # Retrieve each parameter from the dictionary \"parameters\"\n",
    "    #(â‰ˆ 4 lines of code)\n",
    "    # W1 = ...\n",
    "    # b1 = ...\n",
    "    # W2 = ...\n",
    "    # b2 = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    # Implement Forward Propagation to calculate A2 (probabilities)\n",
    "    # (â‰ˆ 4 lines of code)\n",
    "    # Z1 = ...\n",
    "    # A1 = ...\n",
    "    # Z2 = ...\n",
    "    # A2 = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "#     print(W1.shape, X.shape, b1.shape)\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "#     print(A2)\n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    assert(A2.shape == (1, X.shape[1]))\n",
    "    \n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "    \n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a38cd2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_cost\n",
    "\n",
    "def compute_cost(A2, Y):\n",
    "    \"\"\"\n",
    "    Computes the cross-entropy cost given in equation (13)\n",
    "    \n",
    "    Arguments:\n",
    "    A2 -- The sigmoid output of the second activation, of shape (1, number of examples)\n",
    "    Y -- \"true\" labels vector of shape (1, number of examples)\n",
    "\n",
    "    Returns:\n",
    "    cost -- cross-entropy cost given equation (13)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1] # number of examples\n",
    "\n",
    "    # Compute the cross-entropy cost\n",
    "    # (â‰ˆ 2 lines of code)\n",
    "    # logprobs = ...\n",
    "    # cost = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    logprobs = (np.log(A2)*Y) + (np.log(1-A2)*1-Y)\n",
    "#     print(logprobs)\n",
    "    cost = - (np.sum(logprobs))/m \n",
    "#     print(cost)\n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    cost = float(np.squeeze(cost))  # makes sure cost is the dimension we expect. \n",
    "                                    # E.g., turns [[17]] into 17 \n",
    "#     print(cost)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c8377fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: backward_propagation\n",
    "\n",
    "def backward_propagation(parameters, cache, X, Y):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation using the instructions above.\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing our parameters \n",
    "    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\".\n",
    "    X -- input data of shape (2, number of examples)\n",
    "    Y -- \"true\" labels vector of shape (1, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    grads -- python dictionary containing your gradients with respect to different parameters\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # First, retrieve W1 and W2 from the dictionary \"parameters\".\n",
    "    #(â‰ˆ 2 lines of code)\n",
    "    # W1 = ...\n",
    "    # W2 = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    # YOUR CODE ENDS HERE\n",
    "        \n",
    "    # Retrieve also A1 and A2 from dictionary \"cache\".\n",
    "    #(â‰ˆ 2 lines of code)\n",
    "    # A1 = ...\n",
    "    # A2 = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    A1 = cache['A1']\n",
    "    A2 = cache['A2']\n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    # Backward propagation: calculate dW1, db1, dW2, db2. \n",
    "    #(â‰ˆ 6 lines of code, corresponding to 6 equations on slide above)\n",
    "    # dZ2 = ...\n",
    "    # dW2 = ...\n",
    "    # db2 = ...\n",
    "    # dZ1 = ...\n",
    "    # dW1 = ...\n",
    "    # db1 = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = (1/m) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1/m) * np.sum(dZ2, keepdims = True, axis = 1)\n",
    "    dZ1 = np.dot(W2.T , dZ2) * (1 - np.power(A1, 2))\n",
    "    dW1 = (1/m) * np.dot(dZ1, X.T)\n",
    "    db1 = (1/m) * np.sum(dZ1, keepdims = True, axis = 1)\n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c685a4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: update_parameters\n",
    "\n",
    "def update_parameters(parameters, grads, learning_rate = 0.000175):\n",
    "    \"\"\"\n",
    "    Updates parameters using the gradient descent update rule given above\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    grads -- python dictionary containing your gradients \n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "    \"\"\"\n",
    "    # Retrieve a copy of each parameter from the dictionary \"parameters\". Use copy.deepcopy(...) for W1 and W2\n",
    "    #(â‰ˆ 4 lines of code)\n",
    "    # W1 = ...\n",
    "    # b1 = ...\n",
    "    # W2 = ...\n",
    "    # b2 = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    # Retrieve each gradient from the dictionary \"grads\"\n",
    "    #(â‰ˆ 4 lines of code)\n",
    "    # dW1 = ...\n",
    "    # db1 = ...\n",
    "    # dW2 = ...\n",
    "    # db2 = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    dW1 = grads['dW1']\n",
    "    db1 = grads['db1']\n",
    "    dW2 = grads['dW2']\n",
    "    db2 = grads['db2']\n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    # Update rule for each parameter\n",
    "    #(â‰ˆ 4 lines of code)\n",
    "    # W1 = ...\n",
    "    # b1 = ...\n",
    "    # W2 = ...\n",
    "    # b2 = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "260b3e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: nn_model\n",
    "\n",
    "def nn_model(X, Y, n_h, num_iterations = 10000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- dataset of shape (2, number of examples)\n",
    "    Y -- labels of shape (1, number of examples)\n",
    "    n_h -- size of the hidden layer\n",
    "    num_iterations -- Number of iterations in gradient descent loop\n",
    "    print_cost -- if True, print the cost every 1000 iterations\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(3)\n",
    "    n_x = layer_sizes(X, Y)[0]\n",
    "    n_y = layer_sizes(X, Y)[2]\n",
    "    print(n_x, n_y)\n",
    "    \n",
    "    # Initialize parameters\n",
    "    #(â‰ˆ 1 line of code)\n",
    "    # parameters = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "         \n",
    "        #(â‰ˆ 4 lines of code)\n",
    "        # Forward propagation. Inputs: \"X, parameters\". Outputs: \"A2, cache\".\n",
    "        # A2, cache = ...\n",
    "        \n",
    "        # Cost function. Inputs: \"A2, Y\". Outputs: \"cost\".\n",
    "        # cost = ...\n",
    " \n",
    "        # Backpropagation. Inputs: \"parameters, cache, X, Y\". Outputs: \"grads\".\n",
    "        # grads = ...\n",
    " \n",
    "        # Gradient descent parameter update. Inputs: \"parameters, grads\". Outputs: \"parameters\".\n",
    "        # parameters = ...\n",
    "        \n",
    "        # YOUR CODE STARTS HERE\n",
    "        A2, cache = forward_propagation(X, parameters)\n",
    "        cost = compute_cost(A2, Y)\n",
    "        grads = backward_propagation(parameters, cache, X, Y)\n",
    "        parameters = update_parameters(parameters, grads)\n",
    "        \n",
    "        # YOUR CODE ENDS HERE\n",
    "        \n",
    "        # Print the cost every 1000 iterations\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f6e86cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: predict\n",
    "\n",
    "def predict(parameters, X):\n",
    "    \"\"\"\n",
    "    Using the learned parameters, predicts a class for each example in X\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    X -- input data of size (n_x, m)\n",
    "    \n",
    "    Returns\n",
    "    predictions -- vector of predictions of our model (red: 0 / blue: 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Computes probabilities using forward propagation, and classifies to 0/1 using 0.5 as the threshold.\n",
    "    #(â‰ˆ 2 lines of code)\n",
    "    # A2, cache = ...\n",
    "    # predictions = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    A2, cache = forward_propagation(X, parameters)\n",
    "    print(A2)\n",
    "    predictions = (A2 > 0.5)\n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "72be5c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(164, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 164)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = train_x.reshape((7, 652))\n",
    "print(test_x.shape)\n",
    "test_x = test_x.reshape((7, 164))\n",
    "train_y = train_y.reshape([1,652])\n",
    "test_y = test_y.reshape([1, 164])\n",
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4241e0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 1\n",
      "Cost after iteration 0: 1.597757\n",
      "Cost after iteration 100: 1.597923\n",
      "Cost after iteration 200: 1.598087\n",
      "Cost after iteration 300: 1.598251\n",
      "Cost after iteration 400: 1.598415\n",
      "Cost after iteration 500: 1.598578\n",
      "Cost after iteration 600: 1.598740\n",
      "Cost after iteration 700: 1.598902\n",
      "Cost after iteration 800: 1.599063\n",
      "Cost after iteration 900: 1.599223\n"
     ]
    }
   ],
   "source": [
    "parameters = nn_model(train_x, train_y, n_h = 4, num_iterations = 1000, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "10774ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50199    0.50565707 0.49649369 0.50184317 0.5017127  0.49915473\n",
      "  0.49840679 0.49995348 0.50468106 0.4964745  0.49637051 0.50029905\n",
      "  0.49926272 0.5036962  0.50423171 0.50115531 0.50477923 0.50204815\n",
      "  0.50051667 0.50642887 0.50155369 0.49779142 0.49837841 0.49826632\n",
      "  0.49891489 0.50120994 0.49698683 0.49673694 0.49615767 0.50412687\n",
      "  0.50011184 0.50177945 0.49928185 0.49825175 0.50135293 0.50489387\n",
      "  0.49976404 0.50195679 0.5028349  0.4984765  0.49803525 0.49881705\n",
      "  0.49756874 0.50367599 0.49863897 0.49817316 0.50620397 0.50341312\n",
      "  0.50163314 0.50166887 0.50611399 0.49910352 0.50030146 0.5010665\n",
      "  0.5015919  0.49808328 0.50440649 0.49928571 0.49969168 0.50199564\n",
      "  0.49921837 0.49731828 0.49330168 0.49818221 0.50520076 0.4917351\n",
      "  0.49695137 0.49978406 0.49915138 0.50198931 0.49982585 0.50278464\n",
      "  0.49656572 0.49861039 0.50094051 0.49924507 0.49890176 0.50068027\n",
      "  0.50378915 0.49815237 0.4982247  0.4968914  0.50185205 0.50152697\n",
      "  0.49961134 0.50263696 0.49849774 0.5006156  0.50079772 0.49535553\n",
      "  0.5014051  0.49985544 0.49948397 0.49636037 0.49859255 0.50103799\n",
      "  0.49853209 0.49882542 0.50162378 0.49805512 0.50118075 0.50182152\n",
      "  0.49997292 0.49667093 0.4929004  0.50064313 0.49889567 0.49882188\n",
      "  0.49797176 0.50349201 0.50543141 0.49741883 0.50335313 0.50460231\n",
      "  0.50088371 0.49631911 0.49826642 0.49950392 0.49454781 0.49901231\n",
      "  0.4982833  0.49453032 0.50318434 0.50278405 0.50652461 0.50209174\n",
      "  0.5046807  0.50378498 0.50221706 0.49557775 0.5000243  0.49875143\n",
      "  0.49415614 0.50512804 0.49824624 0.50122679 0.49819031 0.5032238\n",
      "  0.49629111 0.49711931 0.50650902 0.50220493 0.49710686 0.50162579\n",
      "  0.49827559 0.49873733 0.5043137  0.50220113 0.50157699 0.49900641\n",
      "  0.49820618 0.50616933 0.49510284 0.4999886  0.50422198 0.50260811\n",
      "  0.50441368 0.50016723 0.50231825 0.49471701 0.49987229 0.5057226\n",
      "  0.50166264 0.5024941  0.49773492 0.49677715 0.49839954 0.50423523\n",
      "  0.50109835 0.50378115 0.50110467 0.49621524 0.49868982 0.49634809\n",
      "  0.50074849 0.50096796 0.50489764 0.49818135 0.49662947 0.50172126\n",
      "  0.49908595 0.50183361 0.50314044 0.50363812 0.49741579 0.49387127\n",
      "  0.50189128 0.5009559  0.49747072 0.50050242 0.50502587 0.498609\n",
      "  0.49534658 0.50517144 0.49545276 0.50093112 0.49713405 0.50462024\n",
      "  0.50059134 0.49870969 0.49815941 0.50016703 0.49771058 0.50042574\n",
      "  0.50370966 0.49355449 0.50120711 0.50314452 0.50493071 0.49851884\n",
      "  0.49975589 0.49936616 0.49471974 0.50089608 0.4999156  0.49662012\n",
      "  0.50061187 0.50108002 0.50070155 0.49747095 0.49772825 0.4948419\n",
      "  0.49954475 0.4950676  0.49784942 0.50662395 0.49917427 0.49782668\n",
      "  0.49688711 0.50046077 0.50254557 0.50474994 0.50290281 0.50223486\n",
      "  0.50046468 0.50326699 0.49971803 0.50185122 0.50558517 0.50002357\n",
      "  0.50015178 0.49495146 0.49795216 0.4985643  0.49582968 0.50637018\n",
      "  0.50629149 0.50043146 0.49607657 0.49610156 0.49863731 0.50008221\n",
      "  0.50315009 0.50387086 0.49357916 0.49630869 0.5029037  0.49347934\n",
      "  0.49835955 0.5044538  0.49587805 0.50041974 0.49963222 0.50130282\n",
      "  0.49914981 0.49778795 0.50732335 0.50250941 0.49697807 0.50398054\n",
      "  0.50049397 0.49686051 0.50038958 0.5007964  0.50472579 0.4941525\n",
      "  0.49593281 0.50137032 0.49661408 0.49966281 0.50658556 0.50227958\n",
      "  0.50168568 0.50106642 0.49732532 0.49956155 0.50071796 0.50119993\n",
      "  0.49833253 0.50411579 0.49699472 0.50437924 0.49455216 0.49997826\n",
      "  0.50119683 0.49779035 0.49895739 0.49724595 0.4986927  0.49461396\n",
      "  0.49886255 0.50586704 0.49648073 0.50331214 0.49658291 0.49844969\n",
      "  0.49787844 0.4996116  0.50101875 0.49833056 0.49792742 0.49657116\n",
      "  0.49857222 0.49916374 0.50013997 0.50218358 0.49938535 0.50358922\n",
      "  0.49654485 0.49980078 0.50023339 0.49916684 0.49759352 0.495446\n",
      "  0.49831271 0.49984754 0.50487713 0.49916166 0.50059163 0.49803943\n",
      "  0.49617955 0.49503504 0.49624573 0.50415467 0.50448486 0.49706145\n",
      "  0.49803264 0.50232047 0.50104655 0.49718179 0.49852638 0.50224866\n",
      "  0.50104816 0.49865412 0.50556616 0.49832124 0.50038246 0.49935449\n",
      "  0.50112864 0.4993734  0.50408815 0.50197174 0.50084059 0.49686995\n",
      "  0.50443607 0.49868498 0.50614488 0.503999   0.49752267 0.50422208\n",
      "  0.49531496 0.50214943 0.4983948  0.50044254 0.49530698 0.49939017\n",
      "  0.50254888 0.49655013 0.50213142 0.50261922 0.49520392 0.49935063\n",
      "  0.49489897 0.49732232 0.49797431 0.50058907 0.49725767 0.50006592\n",
      "  0.50123048 0.49988238 0.50341553 0.49624211 0.50627351 0.49246587\n",
      "  0.49824293 0.49578551 0.49942698 0.50133898 0.5017762  0.4968741\n",
      "  0.49480927 0.50292655 0.50013453 0.49863237 0.49266809 0.49580223\n",
      "  0.50518492 0.4976686  0.50437677 0.49810261 0.49786857 0.49777094\n",
      "  0.49935125 0.50208861 0.4984073  0.50258384 0.50061784 0.50020225\n",
      "  0.50125908 0.49629529 0.50315778 0.497345   0.49656946 0.5009874\n",
      "  0.50360123 0.50204376 0.49768732 0.49887147 0.49954457 0.4957333\n",
      "  0.49755144 0.50430291 0.49563028 0.50208392 0.50337966 0.49828224\n",
      "  0.49888137 0.50145073 0.5033809  0.49835293 0.50218046 0.50389975\n",
      "  0.49445818 0.50141871 0.50010549 0.50509375 0.49732475 0.49653538\n",
      "  0.50174982 0.49710841 0.49883468 0.50033188 0.50120302 0.5026281\n",
      "  0.50190219 0.49947424 0.49463755 0.50012322 0.50234966 0.49348309\n",
      "  0.490982   0.4970688  0.50006339 0.4983829  0.49929654 0.50202302\n",
      "  0.50381802 0.49412643 0.49681373 0.50075895 0.49335182 0.49592336\n",
      "  0.49894551 0.50481316 0.49955446 0.49832767 0.49965648 0.49789863\n",
      "  0.50571111 0.50154946 0.50646483 0.49904867 0.5007157  0.49940437\n",
      "  0.50185979 0.49735881 0.50311869 0.49710717 0.50419335 0.49991828\n",
      "  0.50161263 0.49710679 0.50015519 0.50281094 0.50309489 0.49327181\n",
      "  0.49505978 0.50055749 0.49961322 0.50238346 0.49955962 0.49829669\n",
      "  0.4964301  0.50029951 0.49912032 0.50075023 0.5018735  0.50050484\n",
      "  0.4966472  0.50379796 0.49814965 0.50163482 0.49857254 0.50405772\n",
      "  0.50749172 0.50353466 0.49640397 0.49683388 0.50096478 0.49283707\n",
      "  0.49843392 0.49979734 0.49695108 0.4966804  0.49714514 0.4983919\n",
      "  0.49808657 0.49946455 0.50005694 0.50239788 0.501021   0.50006397\n",
      "  0.50021241 0.49596006 0.50196869 0.50095485 0.50714999 0.50207738\n",
      "  0.50025057 0.49602638 0.49620106 0.49460358 0.50262162 0.49635306\n",
      "  0.50384272 0.49971296 0.50434002 0.49482382 0.50063032 0.4971721\n",
      "  0.49990483 0.49810355 0.49992996 0.50045675 0.49845945 0.49680656\n",
      "  0.50055863 0.49830933 0.49644474 0.50768003 0.49957877 0.49916009\n",
      "  0.49995994 0.50054813 0.50594299 0.49651839 0.50002946 0.49820661\n",
      "  0.50032098 0.5022322  0.50161293 0.49702129 0.49663106 0.49930962\n",
      "  0.50143525 0.50372984 0.49897354 0.50105924 0.49932764 0.49906186\n",
      "  0.49641284 0.50136805 0.49384923 0.49790099 0.50258941 0.50442015\n",
      "  0.49255878 0.4984579  0.49961116 0.50018776 0.50666993 0.50373914\n",
      "  0.50444585 0.49807453 0.49867919 0.50116872 0.49893788 0.50545012\n",
      "  0.49371859 0.49973583 0.50133819 0.50001784 0.5070176  0.49808075\n",
      "  0.49581068 0.502582   0.50361706 0.4972001  0.49815911 0.50463317\n",
      "  0.50432135 0.4962751  0.5054609  0.50381422 0.50281773 0.50194836\n",
      "  0.5011057  0.49555157 0.5000333  0.49838299 0.4984501  0.49872268\n",
      "  0.50005575 0.49794432 0.50279512 0.50211601 0.50644745 0.49747641\n",
      "  0.49329373 0.50304131 0.49981397 0.49810021 0.5008573  0.50658556\n",
      "  0.50262117 0.49823578 0.49498499 0.50071664 0.49843766 0.49999384\n",
      "  0.50149658 0.49723527 0.49840193 0.49627315 0.50385576 0.49328533\n",
      "  0.49766551 0.50296123 0.49826163 0.5035389  0.49265638 0.49857102\n",
      "  0.49796044 0.49830394 0.4989785  0.50281609 0.49581849 0.49135041\n",
      "  0.50392036 0.49811504 0.49855938 0.49988162]]\n",
      "Accuracy: 50%\n"
     ]
    }
   ],
   "source": [
    "predictions = predict(parameters, train_x)\n",
    "print ('Accuracy: %d' % float((np.dot(train_y, predictions.T) + np.dot(1 - train_y, 1 - predictions.T)) / float(train_y.size) * 100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8226798a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49397667 0.50417013 0.50108926 0.49367616 0.50081788 0.50377336\n",
      "  0.5042939  0.50000367 0.494508   0.50386551 0.49690979 0.49992747\n",
      "  0.50358597 0.49838906 0.49993403 0.50030423 0.5053835  0.49509586\n",
      "  0.49933629 0.49748715 0.50384993 0.50324629 0.49478821 0.50399624\n",
      "  0.49937715 0.49697913 0.49975354 0.50431826 0.49870217 0.50228482\n",
      "  0.50143784 0.49419519 0.50151488 0.49644469 0.50505986 0.49424719\n",
      "  0.50363794 0.49808094 0.49984164 0.50027351 0.50014361 0.50472084\n",
      "  0.49753209 0.49519373 0.50309731 0.49687168 0.50417699 0.49825988\n",
      "  0.49827716 0.50327115 0.50226984 0.50299608 0.49562733 0.50081142\n",
      "  0.4986807  0.50654073 0.50068364 0.49754556 0.49750927 0.4970641\n",
      "  0.49757893 0.50155538 0.50029436 0.49541736 0.49967228 0.49789451\n",
      "  0.49559198 0.50254267 0.50304159 0.49869042 0.50055551 0.50147887\n",
      "  0.50171755 0.49719594 0.5034677  0.49875704 0.50018878 0.50356352\n",
      "  0.49906452 0.50363798 0.49410908 0.49490544 0.49581343 0.50388275\n",
      "  0.49829425 0.49998802 0.49777686 0.4984704  0.50189834 0.49771573\n",
      "  0.50622887 0.49965259 0.50045208 0.50445284 0.50412292 0.50195942\n",
      "  0.49813977 0.49981874 0.49800632 0.5002075  0.50375905 0.49926862\n",
      "  0.50200997 0.49526558 0.5002539  0.49649626 0.50113497 0.50173126\n",
      "  0.49510472 0.50474322 0.49993443 0.5072822  0.49810318 0.49888587\n",
      "  0.49760691 0.49761637 0.50581823 0.50109708 0.50479502 0.50388535\n",
      "  0.49573061 0.50054363 0.49808077 0.49909203 0.50564658 0.49688183\n",
      "  0.50206319 0.50059651 0.5026109  0.49905794 0.50103097 0.49266462\n",
      "  0.49984541 0.50031736 0.50204109 0.50108795 0.49978922 0.49887376\n",
      "  0.49204482 0.49550689 0.50018536 0.49999763 0.49804574 0.49855814\n",
      "  0.49922157 0.5006727  0.50012383 0.50024379 0.50019003 0.50220153\n",
      "  0.50325993 0.50722388 0.49953983 0.50667269 0.50192943 0.49979477\n",
      "  0.49420239 0.49196908 0.50605654 0.49821887 0.49898295 0.50297731\n",
      "  0.50027416 0.49862679]]\n",
      "Accuracy: 56%\n"
     ]
    }
   ],
   "source": [
    "predictions = predict(parameters, test_x)\n",
    "print ('Accuracy: %d' % float((np.dot(test_y, predictions.T) + np.dot(1 - test_y, 1 - predictions.T)) / float(test_y.size) * 100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "991d498d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False  True  True False  True  True  True  True False  True False False\n",
      "   True False False  True  True False False False  True  True False  True\n",
      "  False False False  True False  True  True False  True False  True False\n",
      "   True False False  True  True  True False False  True False  True False\n",
      "  False  True  True  True False  True False  True  True False False False\n",
      "  False  True  True False False False False  True  True False  True  True\n",
      "   True False  True False  True  True False  True False False False  True\n",
      "  False False False False  True False  True False  True  True  True  True\n",
      "  False False False  True  True False  True False  True False  True  True\n",
      "  False  True False  True False False False False  True  True  True  True\n",
      "  False  True False False  True False  True  True  True False  True False\n",
      "  False  True  True  True False False False False  True False False False\n",
      "  False  True  True  True  True  True  True  True False  True  True False\n",
      "  False False  True False False  True  True False]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2c2167a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1.\n",
      "  0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0.\n",
      "  0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      "  1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
      "  0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      "  0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bc94cbd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAEGCAYAAADyuIefAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAaIUlEQVR4nO3de5gcdZ3v8fdnJgm5XyY3EgIJF11hESLGuMCKBDiAggIeEBAElT1BFxfO4uqDHkRkH1lvLO5Z8RKQJQK6ELkjJsEgRjgguRCTEBAQA4EEJjcgN5KZnu/5o2qSmkky3ZNMd/WkP6/nqWe6q6urv5NmPvx+9av6lSICMzNL1OVdgJlZNXEompllOBTNzDIcimZmGQ5FM7OMHnkXUA49+vaLnoMa8i7DOqHn6xvyLsE6aR1rV0XE8N3Zx0mT+sXqNYWStp23cPOMiDh5dz6vFHtkKPYc1MC4iy7PuwzrhDHX/r+8S7BO+m386uXd3cfqNQWemrFfSdvWj3ph2O5+Xin2yFA0s+4hgBZa8i6jDYeimeUmCJqitO5zpTgUzSxXbimamaWCoFBllxo7FM0sVy04FM3MgGSgpeBQNDPbxi1FM7NUAE0+pmhmlgjC3Wczs60CCtWViQ5FM8tPckVLdXEomlmORAHlXUQbDkUzy00y0OJQNDMDWs9TdCiamW3V4paimVnCLUUzs4xAFKrsrigORTPLlbvPZmapQGyJ+rzLaMOhaGa5SU7edvfZzGwrD7SYmaUiRCHcUjQz26qli1qKkpYC64AC0BwREyQ1AHcA44ClwCcjYm1H+6muiDazmpIMtPQoaSnRpIgYHxET0udXALMi4l3ArPR5hxyKZpab1oGWUpZddBowNX08FTi92BscimaWq0KopKUEAcyUNE/S5HTdyIhYAZD+HFFsJz6maGa56eQVLcMkzc08nxIRUzLPj46I5ZJGAA9Lem5XanIomlmuWkoffV6VOVa4nYhYnv5slHQPMBF4Q9KoiFghaRTQWOxD3H02s9wkE0LUlbR0RFI/SQNaHwMnAouB+4EL080uBO4rVpNbimaWm0A0dc1lfiOBeyRBkmu/iIjpkuYAd0q6CHgFOKvYjhyKZpabCLrk5O2IeAk4fAfrVwPHd2ZfDkUzy5G67OTtruJQNLPcBF3TUuxKDkUzy5UnmTUzSwXyJLNmZq2SW5xWVwxVVzVmVmPk+RTNzFoFnbqipSIcimaWK7cUzcxSEXJL0cysVTLQ4rv5mZmlfI8WM7OtkoEWH1M0M9vKV7SYmaV8RYuZWTu7cVOqsnAomlluIqCpxaFoZga0dp8dimZmW/mKFitJr/pmfv6J++hVX6BeLcz8ywHc8NRE/mboKq6aNJu+PZtY/vYAvjLzBDY09cq7XAOGj97Cl//jFYaMaCZa4KHbhnLvz4ZzwCGb+Kdvv0qffi288WovvnPJfmxcX10nLOelpk7JkVQAFmVWnR4RS3ey7fqI6F+uWrqjLYV6Pnfvx9nY1JMedQVu/cS9/OHl/fg/xzzG9x4/irnLR3PGwc/yuSMW8J9/nJh3uQYUmsWUa0bz4qK+9OlX4IfTn2f+7AH87+8v48ZrRrPoyf6ceM5qzvxCIz//3qi8y60S1dd9Lmc1myJifGZZWsbP2gOJjU09AehR10KPuhYCMW7Im8xdnvxBPbFsX/7HgS/lWaRlrGnsyYuL+gKwaUM9y17szbBRTYw5cDOLnuwHwNOzB/D3p7yVZ5lVpyW9T0uxpVIqFtGS+kuaJWm+pEWSTtvBNqMkzZa0QNJiSR9K158o6Yn0vdMk1USrsk4t3HX2nfzhc7fwxLIxLHpjJC+sbmDS/ksBOOmgv7B3//X5Fmk7NHLMFg48dBPPze/Ly3/uzZEnvQ3Ah059i+Gjm3Kurnoko8/1JS2VUs5Q7JOG2wJJ9wDvAGdExBHAJOA6pTdpzfgUMCMixpPcrnCBpGHAlcAJ6XvnApe3/zBJkyXNlTS3eeOGMv5aldMSdfzPOz7JcbdcwHtHNnJQw2q+PmsS5753MXd+chp9e26putMZDHr3LfD1m5byk6tGs3F9Pf9++b587DOr+OH05+nTv0Dzluo6hpan1pO3S1kqpZwDLZvScANAUk/gWknHAC3APiQ3sH498545wM3ptvdGxAJJHwYOAR5PM7QX8ET7D4uIKcAUgD6j9o2y/EY5WbdlL556bTR/P3YZtzw9nsn3fwyAsYPf5MPjXsm5Osuq7xF8/aalPHL3EB7/zWAAlr3Ym6+deyAA+xywmQ8e/3aOFVafarvFaSWbGecBw4H3p2H5BtA7u0FEzAaOAV4DbpV0ASDg4cyxyUMi4qIK1p2LIb03MaDXZgD2qm/myH1f5a9rB9PQZyMAIrh4wjzuWHxInmVaG8Hl1y1j2Qu9uXvK8K1rBw1NustS8KnL3uDBW4fmVWDVaR19rpWWYnuDgMaIaJI0CRjbfgNJY4HXIuJGSf2AI4BvATdIOigiXpTUFxgTEc9XsPaKG95vI9ee8Ah1aqFOwYwXD+L3S8dx/mELOfewxQD89i8HcM+z78m5Umv1txM3cMJZa3lpSW9+9PCfAfivfxvFPvtv5mOfWQXA478ZxMz/bsizzKpTbaPPlQzF24EHJM0FFgDP7WCbY4EvS2oC1gMXRMRKSZ8Bfilpr3S7K4E9OhSfXz2UM+84a7v1ty08jNsWHpZDRVbMM0/156TRh2+3fg5w78+Gb/8GI0I010ootj/vMCJWAUd2tG1ETAWm7uD1R4APlKFMM8tZzZy8bWZWTE1d0WJmVgqHoplZypPMmpm1U23nKToUzSw3EdBcZVdlORTNLFfuPpuZpXxM0cysnXAompltU20DLdV1hNPMakpE104IIale0tOSHkyfXy3ptcw0hh8ttg+3FM0sR6LQtaPPlwHPAgMz666PiO+XugO3FM0sVxEqaSlG0hjgFOCm3anHoWhmuenkfIrDWmfXT5fJ7Xb3A+ArJJNYZ31R0kJJN0saUqwmh6KZ5SeS44qlLMCqiJiQWaa07kbSqSTztc5r9wk/Bg4ExgMrgOuKleRjimaWqy4afT4a+Hg6kNIbGCjptog4v3UDSTcCDxbbkVuKZpabSAdaSlk63E/EVyNiTESMA84BHomI8yVlb7B9BrC4WE1uKZpZrqK8t5n7rqTxJIcvlwIXF3uDQ9HMctXVV7RExKPAo+njT3f2/Q5FM8tNMohSXVe0OBTNLFeeEMLMLKPMxxQ7zaFoZrkJRIsnmTUz26bKGooORTPLkQdazMzaqbKmokPRzHLVbVqKkv6TDjI8Ii4tS0VmVjMCaGnpJqEIzK1YFWZWmwLoLi3FiJiafS6pX0RsKH9JZlZLqu08xaInCEk6UtISkim+kXS4pB+VvTIzqw1R4lIhpZw1+QPgJGA1QET8CTimjDWZWc0o7VYElRyMKWn0OSKWSW2KKpSnHDOrOVXWfS4lFJdJOgoISb2AS0m70mZmuyUgqmz0uZTu8+eBS4B9gNdI7nVwSRlrMrOaohKXyijaUoyIVcB5FajFzGpRlXWfSxl9PkDSA5JWSmqUdJ+kAypRnJnVgG44+vwL4E5gFDAamAb8spxFmVmNaD15u5SlQkoJRUXErRHRnC63UXUNXjPrrjpx3+eK6Oja54b04e8kXQH8N0kYng38ugK1mVktqLLR544GWuaRhGBrxdlbAwbwr+Uqysxqh6qs39nRtc/7V7IQM6tBFR5EKUVJV7RIOhQ4BOjdui4ifl6uosysVlR2EKUURUNR0jeAY0lC8SHgI8BjgEPRzHZflbUUSxl9PhM4Hng9Ij4LHA7sVdaqzKx2tJS4VEgp3edNEdEiqVnSQKAR8MnbZrb7utMksxlzJQ0GbiQZkV4PPFXOosysdnSb0edWEfGP6cOfSJoODIyIheUty8xqRncJRUlHdPRaRMwvT0lmZvnpqKV4XQevBXBcF9fSZVr6tPDOwZvyLsM6YcbyBXmXYJ1UP6pr9tNtus8RMamShZhZDQq61WV+Zmbl111aimZmldBtus9mZhVRZaFYyszbknS+pKvS5/tJmlj+0sysJnTDmbd/BBwJnJs+XwfcULaKzKxmKEpfStqfVC/paUkPps8bJD0s6YX055Bi+yglFD8YEZcA7wBExFqgV2klmpkV0aLSltJcRttbMF8BzIqIdwGz0ucdKiUUmyTVkzZgJQ2nopdnm9merKtaipLGAKcAN2VWnwZMTR9PBU4vtp9SQvH/AvcAIyR9i2TasGtLeJ+ZWXGlH1McJmluZpncbk8/AL5C20bbyIhYAZD+HFGsnFKufb5d0jyS6cMEnB4RzxZ5m5lZcZ04XgisiogJO3pB0qlAY0TMk3Ts7pRUyiSz+wEbgQey6yLild35YDMzoKtGlo8GPi7poyR3CBgo6TbgDUmjImKFpFEkUx92qJTu86+BB9Ofs4CXgN/sculmZhlqKW3pSER8NSLGRMQ44BzgkYg4H7gfuDDd7ELgvmL1lNJ9fm+bXyCZPefinWxuZlZNvg3cKeki4BXgrGJv6PQVLRExX9IHdqE4M7PtdfGJ2RHxKPBo+ng1yXhIyUo5pnh55mkdcASwsjMfYma2Q50baKmIUlqKAzKPm0mOLd5VnnLMrOZ0p1BMT9ruHxFfrlA9ZlZruksoSuoREc0d3ZbAzGx3iOIjy5XWUUvxKZLjhwsk3Q9MAza0vhgRd5e5NjPb03XTY4oNwGqSe7IESbgH4FA0s93XjUJxRDryvJhtYdiqyn4NM+u2qixNOgrFeqA/bcOwVZX9GmbWXXWn7vOKiLimYpWYWW3qRqFYXfcdNLM9T3Sv0edOXRpjZrZLuktLMSLWVLIQM6tN3emYoplZ+TkUzcxSFb59aSkcimaWG+Hus5lZGw5FM7Msh6KZWYZD0cws1U1nyTEzKx+HopnZNt3pMj8zs7Jz99nMrJVP3jYza8ehaGaW8BUtZmbtqKW6UtGhaGb58TFFM7O23H02M8tyKJqZbeOWoplZlkPRzCzVze7mZ2ZWVj5P0cysvaiuVHQomlmu3FK0zmkJ9r3qzzQP6cmKLx1Iw6+W02/+WyBRGNiDNyaPpTCkZ95VWuqCiYfQp3+Bujqo7xH8cPrzTP3u3jwxYxASDB7WxL/84BWG7t2cd6nVoVZP3pY0FJiVPt0bKAAr0+cTI2JLJerojgbPWMmW0b2p21QAYO0pI1lz5mgABs1opOHeFaz87H55lmjtfHfaiwwaWtj6/MwvNHLhV14H4N6bhnHb9Xtz2Xdezau8qtMVAy2SegOzgb1Icu1XEfENSVcD/4ttefO1iHioo31VJBQjYjUwHiAtcn1EfL/1dUk9IsL/62ynfs0W+i54i7Uf35vB0xsBiD71W1+v29xCcqjaqlm/Adv+6t/ZVIf8lbXRRaPPm4HjImK9pJ7AY5J+k752fTZvismt+yzpFmAN8D5gvqR1ZMJS0mLg1IhYKul84FKgF/BH4B8jorDjPe85ht/2GqvP2Ye6d9r+qg3TljPgsTW09Knnta8dlFN1tkMKvnbugSA45dOr+ej5qwH4r2/vzW+nNdBvYIHv/urFnIusIkGXDLRERADr06c902WXdly329XsnncDJ0TEl3a2gaSDgbOBoyNiPEnX+7wdbDdZ0lxJcwtvbyhXvRXT9+m3KAzsweb9+2732pqzRvPyfxzK+qOGMPjhVTlUZztz/X0vcMPM5/nW7S9x/y3DWPRkPwA+e8Xr3D5vCcd9Yi333zw85yqri6K0BRjW+jeeLpPb7Eeql7QAaAQejog/pi99UdJCSTdLGlKsnrxDcVoJLb7jgfcDc9Jf+HjggPYbRcSUiJgQERPqB/br+korrM/zG+g3/y3G/vMzjLxhKX2WrGPkj5e22WbdUQ30m/NmLvXZjrUOoAwe1szRJ7/Fc0+3/Z/apDPW8thDg/IorXpFiQusav0bT5cpbXYTUUgbTmOAiZIOBX4MHEhy+G4FcF2xcvIefc426ZppG9K9058CpkbEVytWVRVYffZoVp+dDKj0eXYdgx9q5I0vjKPn6+/QtHfyT9Nv/ls0je7d0W6sgt7ZWEdLC/Tt38I7G+uY9/sBnHf567z2Ui/2OSAZS3xyxiD2PWhzzpVWj3KcvB0Rb0p6FDi53djFjcCDxd6fdyhmLQVOBZB0BLB/un4WcJ+k6yOiUVIDMCAiXs6nzHwNvWM5PVdshjpoHtqLxs/um3dJllq7sgffvCj5z7bQDJPOeJMPTFrHNf8wjlf/shd1dTBiny1c6pHnbSK6ZJJZScOBpjQQ+wAnAN+RNCoiVqSbnQEsLravagrFu4AL0i7yHOB5gIhYIulKYKakOqAJuASomVDcdPAANh08AIDXL9vuyIFViVFjt/CT3/55u/VX3bS08sV0J13TUhwFTJVUT9LjvDMiHpR0q6Tx6acsBS4utqOKh2JEXL2T9ZuAE3fy2h3AHWUsy8xy0hXd54hYSHImS/v1n+7svqqppWhmtSYA36PFzCyjujLRoWhm+fKEEGZmGb7FqZlZq1qdJcfMbEeSk7erKxUdimaWL9+jxcxsG7cUzcxa+ZiimVlW11z73JUcimaWL3efzcxS0WW3I+gyDkUzy5dbimZmGdWViQ5FM8uXWqqr/+xQNLP8BD5528yslQifvG1m1oZD0cwsw6FoZpbyMUUzs7Y8+mxmtlW4+2xmtlXgUDQza6O6es8ORTPLl89TNDPLciiamaUioFBd/WeHopnlyy1FM7MMh6KZWSoA36PFzKxVQPiYoplZIvBAi5lZGz6maGaW4VA0M2vlCSHMzLYJwFOHmZllVFlLsS7vAsyslqWX+ZWydEBSb0lPSfqTpGckfTNd3yDpYUkvpD+HFKvIoWhm+QmIaClpKWIzcFxEHA6MB06W9HfAFcCsiHgXMCt93iGHopnlqyVKWzoQifXp057pEsBpwNR0/VTg9GLlOBTNLF8RpS0wTNLczDI5uxtJ9ZIWAI3AwxHxR2BkRKxIPiZWACOKleOBFjPLT0RnRp9XRcSEne8qCsB4SYOBeyQduisluaVoZvkqvaVY4u7iTeBR4GTgDUmjANKfjcXe71A0sxwFUSiUtHRE0vC0hYikPsAJwHPA/cCF6WYXAvcVq8jdZzPLT9dNHTYKmCqpnqSxd2dEPCjpCeBOSRcBrwBnFduRQ9HM8tUFU4dFxELgfTtYvxo4vjP7ciiaWW4CCE8ya2aWCk8ya2bWRrFBlEpTVNnF2F1B0krg5bzrKJNhwKq8i7BO2VO/s7ERMXx3diBpOsm/TylWRcTJu/N5pdgjQ3FPJmluRyewWvXxd9a9+DxFM7MMh6KZWYZDsfuZkncB1mn+zroRH1M0M8twS9HMLMOhaGaW4ZO3cyapACzKrDo9IpbuZNv1EdG/IoVZhyQNJZneHmBvoACsTJ9PjIgtuRRmu83HFHPWmaBzKFYnSVcD6yPi+5l1PSKiOb+qbFe5+1xlJPWXNEvSfEmLJJ22g21GSZotaYGkxZI+lK4/UdIT6XunSXKAVpCkWyT9u6TfAd+RdLWkf8m8vljSuPTx+end5xZI+mk65ZVVAYdi/vqkfxgLJN0DvAOcERFHAJOA6ySp3Xs+BcyIiPHA4cACScOAK4ET0vfOBS6v2G9hrd5N8h18aWcbSDoYOBs4Ov0OC8B5lSnPivExxfxtSv8wAJDUE7hW0jFAC7APMBJ4PfOeOcDN6bb3RsQCSR8GDgEeTzO0F/BEZX4Fy5iW3iukI8cD7wfmpN9VH0qYJt8qw6FYfc4DhgPvj4gmSUuB3tkNImJ2GpqnALdK+h6wluQOZudWumBrY0PmcTNte2Ot36OAqRHx1YpVZSVz97n6DAIa00CcBIxtv4Gksek2NwI/A44AngSOlnRQuk1fSe+uYN22vaUk3w2SjgD2T9fPAs6UNCJ9rSH9Tq0KuKVYfW4HHpA0F1hAcvOd9o4FviypCVgPXBARKyV9BvilpL3S7a4Eni97xbYzdwEXpPcinkP6XUTEEklXAjMl1QFNwCXsudPddSs+JcfMLMPdZzOzDIeimVmGQ9HMLMOhaGaW4VA0M8twKNYoSYXMtdPTJPXdjX3dIunM9PFNkg7pYNtjJR21C5+xNL2UsaT17bZZ38nPanPNstUWh2Lt2hQR4yPiUGAL8Pnsi7s6QUFE/ENELOlgk2OBToeiWaU4FA3gD8BBaSvud5J+ASySVC/pe5LmSFoo6WIAJX4oaYmkXwMjWnck6VFJE9LHJ6cz9vwpnflnHEn4/nPaSv2QpOGS7ko/Y46ko9P3DpU0U9LTkn5KcmlchyTdK2mepGckTW732nVpLbMkDU/XHShpevqeP0h6T5f8a1q35itaapykHsBHgOnpqonAoRHx1zRY3oqID6RXyTwuaSbwPuBvgPeSTFaxBLi53X6HAzcCx6T7aoiINZJ+QmbuwTSAr4+IxyTtB8wADga+ATwWEddIOgVoE3I78bn0M/qQTLZwV0SsBvoB8yPiS5KuSvf9RZIbSn0+Il6Q9EHgR8Bxu/DPaHsQh2Lt6pNefgZJS/FnJN3apyLir+n6E4HDWo8XklyX/S7gGOCX6WwwyyU9soP9/x0wu3VfEbFmJ3WcABySmR1toKQB6Wd8In3vryWtLeF3ulTSGenjfdNaV5PMNnRHuv424G4lc00eBUzLfPZeWM1zKNauNlOWAaThkJ3lRcA/RcSMdtt9FCh2fahK2AaSQzhHRsSmHdRS8jWoko4lCdgjI2KjpEdpN7tQRqSf+2b7fwMzH1O0jswAvpDO24ikd0vqB8wGzkmPOY4imQy3vSeAD0vaP31vQ7p+HTAgs91Mkq4s6Xbj04ezSSdelfQRYEiRWgcBa9NAfA9JS7VVHdDa2v0USbf8beCvks5KP0OSDi/yGVYDHIrWkZtIjhfOl7QY+ClJ7+Ie4AWSG279GPh9+zdGxEqS44B3S/oT27qvDwBntA60AJcCE9KBnCVsGwX/JnCMpPkk3fhXitQ6HeghaSHwryRTqbXaAPytpHkkxwyvSdefB1yU1vcMsN2tH6z2eJYcM7MMtxTNzDIcimZmGQ5FM7MMh6KZWYZD0cwsw6FoZpbhUDQzy/j/ORJoHZOjOxIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# actual = numpy.random.binomial(1,.9,size = 1000)\n",
    "# predicted = numpy.random.binomial(1,.9,size = 1000)\n",
    "\n",
    "# test_y[np.where(test_y == 1)] = True\n",
    "# test_y[np.where(test_y == 0)] = False\n",
    "\n",
    "# predictions = np.where(predictions == 1, 1., 0.)\n",
    "\n",
    "# print(test_y)\n",
    "# print(predictions)\n",
    "confusion_matrix = metrics.confusion_matrix(test_y[0], predictions[0])\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "055f9186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6463414634146342"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Precision = metrics.precision_score(test_y[0], predictions[0])\n",
    "Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a1553429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5735294117647058"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Specificity = metrics.recall_score(test_y[0], predictions[0], pos_label=0)\n",
    "Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "74232956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5955056179775281"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1_score = metrics.f1_score(test_y[0], predictions[0])\n",
    "F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e917bc10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
